# Video Rendering Pipeline Implementation

## Overview

The video rendering pipeline converts video scripts (generated by CrewAI) into actual MP4 video files. It supports both CPU-friendly baseline rendering and optional GPU-based AI video generation.

## Architecture

### VideoProvider Interface

All video renderers implement the `VideoProvider` interface:

```python
class VideoProvider(ABC):
    def render(video_script_json, options) -> Dict[str, Any]
    def is_available() -> bool
    def get_supported_resolutions() -> List[Tuple[int, int]]
```

### Implementations

1. **BaselineVideoRenderer** (CPU-friendly, default)
   - Uses PIL/Pillow for image generation
   - Uses MoviePy for video assembly
   - Uses FFmpeg for final encoding
   - Creates slides/frames from scenes with:
     - Background (solid color, placeholder, or uploaded image)
     - Text overlays + scene titles
     - Narration audio (if available from voiceover_audio artifact)
   - Assembles into MP4

2. **ComfyUIVideoProvider** (GPU, optional)
   - Requires `ENABLE_AI_VIDEO=true` environment variable
   - Calls ComfyUI HTTP API for AI-generated video clips
   - Uses AnimateDiff or SVD models
   - Placeholder implementation (requires ComfyUI server setup)

## Data Model

### ContentArtifact Types

New artifact types for video rendering:

- `storyboard` (JSON + optional images)
- `storyboard_image` (file artifacts - PNG images)
- `video_clip` (file artifacts - MP4 clips per scene)
- `final_video` (file artifact - final MP4)

### Artifact Metadata

`content_json` stores:
```json
{
  "storage_key": "videos/20240112_123456_abc123.mp4",
  "storage_url": "/v1/storage/videos/20240112_123456_abc123.mp4",
  "duration_sec": 30.5,
  "resolution": [1920, 1080],
  "fps": 30,
  "scenes_count": 5,
  "renderer": "baseline",
  "model_used": "baseline"
}
```

## API Endpoints

### POST /v1/content/video/render

Render video from a job's video script.

**Request:**
```json
{
  "job_id": 123,
  "resolution": [1920, 1080],
  "fps": 30,
  "background_type": "solid",
  "background_color": "#000000",
  "background_image_path": null,
  "include_narration": true,
  "renderer": "baseline"
}
```

**Response:**
```json
{
  "job_id": 123,
  "status": "processing",
  "message": "Video rendering started"
}
```

### GET /v1/content/jobs/{job_id}

Returns job details including all artifacts (video artifacts included).

## SSE Events

Video rendering emits the following SSE events:

1. **video_render_started**
   ```json
   {
     "type": "video_render_started",
     "job_id": 123,
     "renderer": "baseline",
     "resolution": [1920, 1080],
     "fps": 30,
     "scenes_count": 5
   }
   ```

2. **scene_started**
   ```json
   {
     "type": "scene_started",
     "job_id": 123,
     "scene_index": 0,
     "scene_title": "Hook"
   }
   ```

3. **scene_completed**
   ```json
   {
     "type": "scene_completed",
     "job_id": 123,
     "scene_index": 0,
     "scene_title": "Hook"
   }
   ```

4. **artifact_ready** (for storyboard_image, video_clip, final_video)
   ```json
   {
     "type": "artifact_ready",
     "job_id": 123,
     "artifact_type": "final_video",
     "artifact_id": 456,
     "metadata": { ... }
   }
   ```

5. **video_render_completed**
   ```json
   {
     "type": "video_render_completed",
     "job_id": 123,
     "artifact_id": 456,
     "duration_sec": 30.5,
     "resolution": [1920, 1080],
     "storage_url": "/v1/storage/videos/..."
   }
   ```

6. **video_render_failed**
   ```json
   {
     "type": "video_render_failed",
     "job_id": 123,
     "message": "Error message",
     "error_type": "RuntimeError"
   }
   ```

## Configuration

### Environment Variables

- `ENABLE_AI_VIDEO`: Set to `"true"` to enable ComfyUI renderer (default: `false`)
- `COMFYUI_API_URL`: ComfyUI API URL (default: `http://localhost:8188`)

### Dependencies

Required Python packages:
- `pillow>=10.0.0` (PIL)
- `moviepy>=1.0.3`

Required system binary:
- `ffmpeg` (must be in PATH)

#### Installing FFmpeg

**Check Installation:**
```bash
python scripts/check_ffmpeg.py
# Or
make check-deps
```

**Windows:**
```powershell
# Using Chocolatey
choco install ffmpeg

# Using winget
winget install ffmpeg

# Or download from: https://www.gyan.dev/ffmpeg/builds/
# Extract and add 'bin' folder to PATH

# Or use installation script
powershell -ExecutionPolicy Bypass -File scripts/install_ffmpeg.ps1
```

**macOS:**
```bash
brew install ffmpeg

# Or use installation script
bash scripts/install_ffmpeg.sh
```

**Linux:**
```bash
# Ubuntu/Debian
sudo apt-get update && sudo apt-get install ffmpeg

# Fedora
sudo dnf install ffmpeg

# Arch
sudo pacman -S ffmpeg

# Or use installation script
bash scripts/install_ffmpeg.sh
```

**Using Makefile:**
```bash
make install-ffmpeg  # Automatically detects platform and installs
```

**Verify Installation:**
```bash
python scripts/check_ffmpeg.py
# Or
ffmpeg -version
```

## Usage Example

```python
# 1. Generate video script (via CrewAI)
POST /v1/content/generate
{
  "topic": "Introduction to AI",
  "content_types": ["video"]
}

# 2. Optionally generate voiceover
POST /v1/content/voiceover
{
  "job_id": 123
}

# 3. Render video
POST /v1/content/video/render
{
  "job_id": 123,
  "resolution": [1920, 1080],
  "fps": 30,
  "background_type": "solid",
  "background_color": "#1a1a2e",
  "include_narration": true,
  "renderer": "baseline"
}

# 4. Stream progress
GET /v1/content/jobs/123/stream

# 5. Get final video
GET /v1/content/jobs/123
# Response includes final_video artifact with storage_url

# 6. Download video
GET /v1/storage/videos/20240112_123456_abc123.mp4
```

## Video Script Structure

The video script JSON should have:

```json
{
  "hook": "Hook text (15-30 seconds)",
  "scenes": [
    {
      "title": "Scene Title",
      "content": "Scene content text",
      "duration_seconds": 5.0
    }
  ],
  "conclusion": "Conclusion with CTA"
}
```

If `scenes` is empty, the renderer will create scenes from `hook` and `conclusion`.

## Background Options

1. **solid**: Solid color background (default: `#000000`)
2. **placeholder**: Gradient placeholder background
3. **upload**: Use uploaded image (requires `background_image_path`)

## Storage

Videos are stored using the existing `StorageProvider` abstraction:
- Local filesystem for development (`./storage/videos/`)
- S3-compatible for production (configurable)

## Limitations

- Baseline renderer creates static slides (no animation)
- ComfyUI renderer requires separate ComfyUI server setup
- FFmpeg must be installed and in PATH
- Large videos may take significant time to render

## Future Enhancements

- Support for animated transitions between scenes
- Custom fonts and styling options
- Image overlays and effects
- Multiple audio tracks
- Subtitle/caption support
- Video preview/thumbnail generation

